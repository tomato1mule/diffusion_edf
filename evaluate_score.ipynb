{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_JIT_USE_NNC_NOT_NVFUSER\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Optional, Union, Iterable\n",
    "import datetime\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "from e3nn import o3\n",
    "from open3d.visualization.tensorboard_plugin import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from diffusion_edf.embedding import NodeEmbeddingNetwork\n",
    "from diffusion_edf.data import SE3, PointCloud, TargetPoseDemo, DemoSequence, DemoSeqDataset, load_demos, save_demos\n",
    "from diffusion_edf.preprocess import Rescale, NormalizeColor, Downsample, PointJitter, ColorJitter\n",
    "from diffusion_edf.wigner import TransformFeatureQuaternion\n",
    "from diffusion_edf.score_model import ScoreModel\n",
    "from diffusion_edf import transforms\n",
    "from diffusion_edf.loss import SE3DenoisingDiffusion\n",
    "from diffusion_edf.utils import sample_reference_points\n",
    "from diffusion_edf.dist import diffuse_isotropic_se3, adjoint_inv_tr_isotropic_se3_score\n",
    "\n",
    "\n",
    "\n",
    "torch.set_printoptions(precision=4, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_len = 0.01\n",
    "scene_voxel_size = 0.01\n",
    "grasp_voxel_size = 0.01\n",
    "\n",
    "scene_voxel_size = scene_voxel_size / unit_len\n",
    "grasp_voxel_size = grasp_voxel_size / unit_len\n",
    "\n",
    "\n",
    "rescale_fn = Rescale(rescale_factor=1/unit_len)\n",
    "recover_scale_fn = Rescale(rescale_factor=unit_len)\n",
    "normalize_color_fn = NormalizeColor(color_mean = torch.tensor([0.5, 0.5, 0.5]), color_std = torch.tensor([0.5, 0.5, 0.5]))\n",
    "recover_color_fn = NormalizeColor(color_mean = -normalize_color_fn.color_mean / normalize_color_fn.color_std, color_std = 1 / normalize_color_fn.color_std)\n",
    "\n",
    "\n",
    "scene_proc_fn = Compose([rescale_fn,\n",
    "                         Downsample(voxel_size=scene_voxel_size, coord_reduction=\"average\"),\n",
    "                         normalize_color_fn])\n",
    "scene_unproc_fn = Compose([recover_color_fn, recover_scale_fn])\n",
    "grasp_proc_fn = Compose([rescale_fn,\n",
    "                         Downsample(voxel_size=grasp_voxel_size, coord_reduction=\"average\"),\n",
    "                         normalize_color_fn])\n",
    "grasp_unproc_fn = Compose([recover_color_fn, recover_scale_fn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "device = 'cuda:0'\n",
    "compile = False\n",
    "\n",
    "irreps_input = o3.Irreps('3x0e')\n",
    "irreps_node_embedding = o3.Irreps('32x0e+16x1e+8x2e') #o3.Irreps('128x0e+64x1e+32x2e')\n",
    "irreps_sh = o3.Irreps('1x0e+1x1e+1x2e')\n",
    "fc_neurons = [128, 64, 64]\n",
    "num_heads = 4\n",
    "alpha_drop = 0.2\n",
    "proj_drop = 0.0\n",
    "drop_path_rate = 0.0\n",
    "irreps_mlp_mid = 2\n",
    "n_scales = 4\n",
    "pool_ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model = ScoreModel(irreps_input = irreps_input,\n",
    "                         irreps_emb_init = irreps_node_embedding,\n",
    "                         irreps_sh = irreps_sh,\n",
    "                         fc_neurons_init = [32, 16, 16],\n",
    "                         num_heads = 4,\n",
    "                         n_scales = 4,\n",
    "                         pool_ratio = 0.3,\n",
    "                         dim_mult = [1, 1, 2, 2],\n",
    "                         n_layers = 2,\n",
    "                         gnn_radius = 2.0,\n",
    "                         cutoff_radius = 4.0,\n",
    "                         weight_feature_dim = 20,\n",
    "                         query_downsample_ratio = 0.7,\n",
    "                         device=device,\n",
    "                         deterministic = False,\n",
    "                         compile_head = compile)\n",
    "\n",
    "score_model = score_model.to(device).eval()\n",
    "# optimizer = torch.optim.Adam(list(score_model.parameters()), lr=1e-4, betas=(0.9, 0.98), eps=1e-09, weight_decay=1e-4, amsgrad=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "trainset = DemoSeqDataset(dataset_dir=\"demo/test_demo\", annotation_file=\"data.yaml\", device=device)\n",
    "train_dataloader = DataLoader(trainset, shuffle=False, collate_fn=lambda x:x)\n",
    "eval_data = []\n",
    "for data in train_dataloader:\n",
    "    eval_data += data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file: Optional[str] = \"runs/2023_04_20_21-28-29/checkpoint/1911.pt\"\n",
    "\n",
    "if checkpoint_file is not None:\n",
    "    checkpoint = torch.load(checkpoint_file)\n",
    "    score_model.load_state_dict(checkpoint['score_model_state_dict'])\n",
    "    # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    steps = checkpoint['steps']\n",
    "    print(f\"Successfully Loaded checkpoint @ epoch: {epoch} (steps: {steps})\")\n",
    "else:\n",
    "    print(f\"Initialize without loading from checkpoint.\")\n",
    "    epoch = 0\n",
    "    steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_seq: DemoSequence = eval_data[0]\n",
    "demo: TargetPoseDemo = demo_seq[1]\n",
    "\n",
    "scene_raw: PointCloud = demo.scene_pc\n",
    "grasp_raw: PointCloud = demo.grasp_pc\n",
    "target_poses_raw: SE3 = demo.target_poses\n",
    "\n",
    "scene_proc: PointCloud = scene_proc_fn(scene_raw).to(device)\n",
    "grasp_proc: PointCloud = grasp_proc_fn(grasp_raw).to(device)\n",
    "target_poses: SE3 = rescale_fn(target_poses_raw).to(device)\n",
    "T_target: torch.Tensor = target_poses.poses\n",
    "\n",
    "x_ref, n_neighbors = sample_reference_points(PointCloud.transform_pcd(scene_proc, target_poses.inv())[0].points, grasp_proc.points, r=3)\n",
    "\n",
    "min_time = 0.01 #1e-3\n",
    "max_time = 0.03  \n",
    "time_in = (min_time/max_time + torch.rand(1, dtype=T_target.dtype, device=T_target.device) * (1-min_time/max_time))*max_time\n",
    "lin_mult = 10.\n",
    "std = torch.sqrt(time_in) * lin_mult\n",
    "eps = time_in / 2\n",
    "\n",
    "T, delta_T, gt_score, gt_score_ref = diffuse_isotropic_se3(T0 = T_target, eps=eps, std=std, N=1, angular_first=True, double_precision=True)\n",
    "T, delta_T, gt_score = T.squeeze(0), delta_T.squeeze(0), gt_score.squeeze(0)\n",
    "target_score = gt_score_ref * torch.tensor([2*torch.sqrt(eps), 2*torch.sqrt(eps), 2*torch.sqrt(eps), std, std, std], device=eps.device, dtype=eps.dtype)\n",
    "\n",
    "key_feature = scene_proc.colors\n",
    "key_coord = scene_proc.points\n",
    "key_batch = torch.zeros(len(key_coord), device=device, dtype=torch.long)\n",
    "query_feature = grasp_proc.colors\n",
    "query_coord = grasp_proc.points\n",
    "query_batch = torch.zeros(len(query_coord), device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score, query, query_info, key_info = score_model(T=T,\n",
    "#                                                     key_feature=key_feature, key_coord=key_coord, key_batch=key_batch,\n",
    "#                                                     query_feature=query_feature, query_coord=query_coord, query_batch=query_batch,\n",
    "#                                                     info_mode='NONE', angular_first= True, time=time_in)\n",
    "# score_ref = adjoint_inv_tr_isotropic_se3_score(x_ref=-x_ref, score=score, angular_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    query, query_info = score_model._get_query(node_feature=query_feature,\n",
    "                                            node_coord=query_coord,\n",
    "                                            batch=query_batch,\n",
    "                                            info_mode='NONE')\n",
    "    key_gnn_outputs = score_model.key_model.get_gnn_outputs(node_feature=key_feature, node_coord=key_coord, batch=key_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max = time_in\n",
    "anneal_mult = 3\n",
    "N_anneal = 100\n",
    "dt = torch.tensor([t_max * anneal_mult / N_anneal], dtype=T.dtype, device=T.device)\n",
    "print(t_max.item(), dt.item())\n",
    "\n",
    "T_next = T\n",
    "for n in tqdm(range(N_anneal)):\n",
    "    t = t_max - dt/anneal_mult * n\n",
    "\n",
    "    with torch.no_grad():\n",
    "        time_emb = score_model.get_time_emb(t)\n",
    "        score, key_extractor_info = score_model.get_score(T=T_next, query=query, key_gnn_outputs=key_gnn_outputs, time_emb = time_emb, angular_first=True)\n",
    "\n",
    "    std = torch.sqrt(time_in) * lin_mult\n",
    "    eps = time_in / 2\n",
    "    disp = score / torch.tensor([2*torch.sqrt(eps), 2*torch.sqrt(eps), 2*torch.sqrt(eps), std, std, std], device=eps.device, dtype=eps.dtype) * (0.5 * dt)\n",
    "    disp = disp + (torch.randn_like(score) * torch.sqrt(dt))\n",
    "\n",
    "    L = T_next.detach()[...,score_model.q_indices] * score_model.q_factor\n",
    "    q, x = T_next[...,:4], T_next[...,4:]\n",
    "    dq = torch.einsum('...ij,...j->...i', L, disp[...,:3])\n",
    "    dx = transforms.quaternion_apply(q, disp[...,3:])\n",
    "    q_next = transforms.normalize_quaternion(q + dq)\n",
    "    T_next = torch.cat([q_next, x+dx], dim=-1)\n",
    "\n",
    "    # dT = transforms.se3_exp_map(torch.cat([disp[..., 3:], disp[..., :3]], dim=-1))\n",
    "    # dT = torch.cat([transforms.matrix_to_quaternion(dT[..., :3, :3]), dT[..., :3, 3]], dim=-1)\n",
    "    # T_next = transforms.multiply_se3(T_next, dT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pose_pcd = PointCloud.merge(scene_raw, grasp_raw.transformed(target_poses_raw)[0])\n",
    "diffused_pose_pcd = PointCloud.merge(scene_raw, grasp_raw.transformed( recover_scale_fn(SE3(T.detach())) )[0])\n",
    "denoised_pose_pcd = PointCloud.merge(scene_raw, grasp_raw.transformed( recover_scale_fn(SE3(T_next.detach())) )[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_pose_pcd.show(width=800, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffused_pose_pcd.show(width=800, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_edf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79a0085b6cf04e1cff261ad12d41cff4e1530d9e68d1f8fc6bd159a2915452c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
